{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"infogan.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1hAfinJcLWe96bho7YGIy6lOjcDDfyfMf","authorship_tag":"ABX9TyPt5tWUbV2vmPGwNYOMq0ia"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lcIaPYQJEU_e","executionInfo":{"status":"ok","timestamp":1624471912744,"user_tz":-480,"elapsed":504,"user":{"displayName":"成漢恩","photoUrl":"","userId":"06396745810117539540"}},"outputId":"d1ce3923-e4d8-4809-ba3e-1ed3e698df7a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aotwpkOnEXbx"},"source":["!cd /content/drive/MyDrive/張雲南/infogan"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jn1zHO3uDmxC","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1624478368840,"user_tz":-480,"elapsed":4697888,"user":{"displayName":"成漢恩","photoUrl":"","userId":"06396745810117539540"}},"outputId":"ea8bab04-cb73-4bb7-ea6a-727eb9e6a14b"},"source":["import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","from tensorflow.keras.layers import Dense, Input, BatchNormalization, LeakyReLU, Dropout\n","from tensorflow.keras.layers import Conv2D, Flatten, Reshape, Conv2DTranspose, ReLU\n","import time\n","import os\n","import matplotlib.pyplot as plt\n","\n","#----------------------- utils -----------------------\n","\n","_b_acc = None\n","_c_acc = None\n","\n","\n","def binary_accuracy(label, pred):\n","    global _b_acc\n","    if _b_acc is None:\n","        _b_acc = tf.keras.metrics.BinaryAccuracy()\n","    _b_acc.reset_states()\n","    _b_acc.update_state(label, pred)\n","    return _b_acc.result()\n","\n","def class_accuracy(label, pred):\n","    global _c_acc\n","    if _c_acc is None:\n","        _c_acc = tf.keras.metrics.SparseCategoricalAccuracy()\n","    _c_acc.reset_states()\n","    _c_acc.update_state(label, pred)\n","    return _c_acc.result()\n","\n","def save_weights(model):\n","    name = model.__class__.__name__.lower()\n","    os.makedirs(\"./models/{}\".format(name), exist_ok=True)\n","    model.save_weights(\"./models/{}/model.ckpt\".format(name))\n","\n","# ------------------- get_half_batch_ds -------------------\n","\n","def _process_x(x):\n","    return tf.expand_dims(tf.cast(x, tf.float32), axis=3) / 255. * 2 - 1\n","\n","def get_half_batch_ds(batch_size):\n","    return get_ds(batch_size//2)\n","\n","def get_ds(batch_size):\n","    (x, y), _ = keras.datasets.mnist.load_data()\n","    x = _process_x(x)\n","    y = tf.cast(y, tf.int32)\n","    ds = tf.data.Dataset.from_tensor_slices((x, y)).cache().shuffle(1024).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n","    return ds\n","\n","# ------------------- gan_cnn -------------------\n","\n","def mnist_uni_gen_cnn(input_shape):\n","    return keras.Sequential([\n","        # [n, latent] -> [n, 7 * 7 * 128] -> [n, 7, 7, 128]\n","        Dense(7 * 7 * 128, input_shape=input_shape),\n","        BatchNormalization(),\n","        ReLU(),\n","        Reshape((7, 7, 128)),\n","        # -> [n, 14, 14, 64]\n","        Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same'),\n","        BatchNormalization(),\n","        ReLU(),\n","        # -> [n, 28, 28, 32]\n","        Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same'),\n","        BatchNormalization(),\n","        ReLU(),\n","        # -> [n, 28, 28, 1]\n","        Conv2D(1, (4, 4), padding='same', activation=keras.activations.tanh)\n","    ])\n","\n","\n","def mnist_uni_disc_cnn(input_shape=(28, 28, 1), use_bn=True):\n","    model = keras.Sequential()\n","    # [n, 28, 28, n] -> [n, 14, 14, 64]\n","    model.add(Conv2D(64, (4, 4), strides=(2, 2), padding='same', input_shape=input_shape))\n","    if use_bn:\n","        model.add(BatchNormalization())\n","    model.add(LeakyReLU())\n","    model.add(Dropout(0.3))\n","    # -> [n, 7, 7, 128]\n","    model.add(Conv2D(128, (4, 4), strides=(2, 2), padding='same'))\n","    if use_bn:\n","        model.add(BatchNormalization())\n","    model.add(LeakyReLU())\n","    model.add(Dropout(0.3))\n","    model.add(Flatten())\n","    return model\n","\n","# ----------------------------------------------------------\n","\n","def save_gan(model, ep, **kwargs):\n","    img_label = np.arange(0, model.label_dim).astype(np.int32).repeat(10, axis=0)\n","    img_style = np.concatenate([np.linspace(-model.style_scale, model.style_scale, 10)] * 10).reshape((100, 1)).repeat(model.style_dim, axis=1).astype(np.float32)\n","    img_info = img_label, img_style\n","    imgs = model.predict(img_info)\n","    _save_gan(ep, imgs, show_label=False)\n","    \n","    plt.clf()\n","    plt.close()\n","\n","def _save_gan(ep, imgs, show_label=False, nc=10, nr=10):\n","    if not isinstance(imgs, np.ndarray):\n","        imgs = imgs.numpy()\n","    if imgs.ndim > 3:\n","        imgs = np.squeeze(imgs, axis=-1)\n","    imgs = _img_recenter(imgs)\n","    plt.clf()\n","    plt.figure(0, (nc * 2, nr * 2))\n","    for c in range(nc):\n","        for r in range(nr):\n","            i = r * nc + c\n","            plt.subplot(nr, nc, i + 1)\n","            plt.imshow(imgs[i], cmap=\"gray_r\")\n","            plt.axis(\"off\")\n","    plt.savefig('/content/drive/MyDrive/張雲南/infogan/img/' + f'{ep}.png')\n","    plt.close()\n","\n","def _img_recenter(img):\n","    return (img + 1) * 255 / 2\n","\n","# ----------------------------------------------------------\n","\n","class InfoGAN(keras.Model):\n","    \"\"\"\n","    discriminator 图片 预测 真假\n","    q net 图片 预测 c  (c可以理解为 虚拟类别 或 虚拟风格)\n","    generator z&c 生成 图片\n","    \"\"\"\n","    def __init__(self, rand_dim, style_dim, label_dim, img_shape, fix_std=True, style_scale=2):\n","        super().__init__()\n","        self.rand_dim, self.style_dim, self.label_dim = rand_dim, style_dim, label_dim\n","        self.img_shape = img_shape\n","        self.fix_std = fix_std\n","        self.style_scale = style_scale\n","\n","        self.g = self._get_generator()\n","        self.d = self._get_discriminator()\n","\n","        self.opt = keras.optimizers.Adam(0.0002, beta_1=0.5)\n","        self.loss_bool = keras.losses.BinaryCrossentropy(from_logits=True, reduction=\"none\")\n","\n","    def call(self, img_info, training=None, mask=None):\n","        img_label, img_style = img_info\n","        noise = tf.random.normal((len(img_label), self.rand_dim))\n","        if isinstance(img_label, np.ndarray):\n","            img_label = tf.convert_to_tensor(img_label, dtype=tf.int32)\n","        if isinstance(img_style, np.ndarray):\n","            img_style = tf.convert_to_tensor(img_style, dtype=tf.float32)\n","        return self.g.call([noise, img_label, img_style], training=training)\n","\n","    def _get_discriminator(self):\n","        img = Input(shape=self.img_shape)\n","        s = keras.Sequential([\n","            mnist_uni_disc_cnn(self.img_shape),\n","            Dense(32),\n","            BatchNormalization(),\n","            LeakyReLU(),\n","            Dropout(0.5),\n","        ])\n","        style_dim = self.style_dim if self.fix_std else self.style_dim * 2\n","        q = keras.Sequential([\n","            Dense(16, input_shape=(32,)),\n","            BatchNormalization(),\n","            LeakyReLU(),\n","            Dense(style_dim+self.label_dim)\n","        ], name=\"recognition\")\n","        o = s(img)\n","        o_bool = Dense(1)(o)\n","        o_q = q(o)\n","        if self.fix_std:\n","            q_style = self.style_scale*tf.tanh(o_q[:, :style_dim])\n","        else:\n","            q_style = tf.concat(\n","                (self.style_scale * tf.tanh(o_q[:, :style_dim//2]), tf.nn.relu(o_q[:, style_dim//2:style_dim])),\n","                axis=1)\n","        q_label = o_q[:, -self.label_dim:]\n","        model = keras.Model(img, [o_bool, q_style, q_label], name=\"discriminator\")\n","        model.summary()\n","        return model\n","\n","    def _get_generator(self):\n","        latent_dim = self.rand_dim + self.label_dim + self.style_dim\n","        noise = Input(shape=(self.rand_dim,))\n","        style = Input(shape=(self.style_dim, ))\n","        label = Input(shape=(), dtype=tf.int32)\n","        label_onehot = tf.one_hot(label, depth=self.label_dim)\n","        model_in = tf.concat((noise, label_onehot, style), axis=1)\n","        s = mnist_uni_gen_cnn((latent_dim,))\n","        o = s(model_in)\n","        model = keras.Model([noise, label, style], o, name=\"generator\")\n","        model.summary()\n","        return model\n","\n","# ------------------------------------------- high light -----------------------------------------------------\n","# info_loss (q_model loss)\n","    def loss_mutual_info(self, style, pred_style, label, pred_label):\n","        # label loss\n","        categorical_loss = keras.losses.sparse_categorical_crossentropy(label, pred_label, from_logits=True)  \n","\n","        # 選擇 std 為固定還是隨機\n","        if self.fix_std:\n","            style_mean = pred_style\n","            style_std = tf.ones_like(pred_style)\n","        else:\n","            split = pred_style.shape[1]//2\n","            style_mean, style_std = pred_style[:split], pred_style[split:]\n","            style_std = tf.sqrt(tf.exp(style_std))\n","\n","        # continuous latent code loss\n","        epsilon = (style - style_mean) / (style_std + 1e-5)\n","        ll_continuous = tf.reduce_sum(\n","            - 0.5 * tf.math.log(2 * np.pi) - tf.math.log(style_std + 1e-5) - 0.5 * tf.square(epsilon),\n","            axis=1,\n","        )\n","\n","        # loss\n","        loss = categorical_loss - ll_continuous\n","        return loss\n","\n","# --------------------------------------------------------------------------------------------------------------\n","\n","    def train_d(self, real_fake_img, real_fake_d_label, fake_img_label, fake_style):\n","        with tf.GradientTape() as tape:\n","            pred_bool, pred_style, pred_class = self.d.call(real_fake_img, training=True)\n","            info_split = len(real_fake_d_label)\n","            real_fake_pred_bool = pred_bool[:info_split]\n","            loss_bool = self.loss_bool(real_fake_d_label, real_fake_pred_bool)\n","            fake_pred_style = pred_style[-info_split:]\n","            fake_pred_label = pred_class[-info_split:]\n","            loss_info = self.loss_mutual_info(fake_style, fake_pred_style, fake_img_label, fake_pred_label)\n","            loss = tf.reduce_mean(loss_bool + LAMBDA * loss_info)\n","        grads = tape.gradient(loss, self.d.trainable_variables)\n","        self.opt.apply_gradients(zip(grads, self.d.trainable_variables))\n","        return loss, binary_accuracy(real_fake_d_label, real_fake_pred_bool), class_accuracy(fake_img_label, fake_pred_label)\n","\n","    def train_g(self, random_img_label, random_img_style):\n","        d_label = tf.ones((len(random_img_label), 1), tf.float32)   # let d think generated images are real\n","        with tf.GradientTape() as tape:\n","            g_img = self.call([random_img_label, random_img_style], training=True)\n","            pred_bool, pred_style, pred_class = self.d.call(g_img, training=False)\n","            loss_bool = self.loss_bool(d_label, pred_bool)\n","            loss_info = self.loss_mutual_info(random_img_style, pred_style, random_img_label, pred_class)\n","            loss = tf.reduce_mean(loss_bool + LAMBDA * loss_info)\n","        grads = tape.gradient(loss, self.g.trainable_variables)\n","        self.opt.apply_gradients(zip(grads, self.g.trainable_variables))\n","        return loss, g_img, binary_accuracy(d_label, pred_bool)\n","\n","    def step(self, real_img):\n","        random_img_label = tf.convert_to_tensor(np.random.randint(0, 10, len(real_img)*2), dtype=tf.int32)\n","        random_img_style = tf.random.uniform((len(real_img)*2, self.style_dim), -self.style_scale, self.style_scale)\n","        g_loss, g_img, g_bool_acc = self.train_g(random_img_label, random_img_style)\n","\n","        real_fake_img = tf.concat((real_img, g_img), axis=0)    # 32+64\n","        real_fake_d_label = tf.concat(      # 32+32\n","            (tf.ones((len(real_img), 1), tf.float32), tf.zeros((len(g_img)//2, 1), tf.float32)), axis=0)\n","        d_loss, d_bool_acc, d_class_acc = self.train_d(real_fake_img, real_fake_d_label, random_img_label, random_img_style)\n","        return d_loss, d_bool_acc, g_loss, g_bool_acc, random_img_label, d_class_acc\n","\n","\n","def train(gan, ds):\n","    t0 = time.time()\n","    for ep in range(EPOCH):\n","        for t, (real_img, _) in enumerate(ds):\n","            d_loss, d_bool_acc, g_loss, g_bool_acc, g_img_label, d_class_acc = gan.step(real_img)\n","            if t % 400 == 0:\n","                t1 = time.time()\n","                print(\"ep={} | time={:.1f}|t={}|d_acc={:.2f}|d_classacc={:.2f}|g_acc={:.2f}|d_loss={:.2f}|g_loss={:.2f}\".format(\n","                    ep, t1-t0, t, d_bool_acc.numpy(), g_bool_acc.numpy(), d_class_acc.numpy(), d_loss.numpy(), g_loss.numpy(), ))\n","                t0 = t1\n","        save_gan(gan, ep)\n","    save_weights(gan)\n","\n","\n","if __name__ == \"__main__\":\n","    STYLE_DIM = 2\n","    LABEL_DIM = 10\n","    RAND_DIM = 8\n","    LAMBDA = 1\n","    IMG_SHAPE = (28, 28, 1)\n","    FIX_STD = True\n","    STYLE_SCALE = 1\n","    BATCH_SIZE = 64\n","    EPOCH = 40\n","\n","    d = get_half_batch_ds(BATCH_SIZE)\n","    m = InfoGAN(RAND_DIM, STYLE_DIM, LABEL_DIM, IMG_SHAPE, FIX_STD, STYLE_SCALE)\n","    train(m, d)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"generator\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_19 (InputLayer)           [(None,)]            0                                            \n","__________________________________________________________________________________________________\n","input_17 (InputLayer)           [(None, 8)]          0                                            \n","__________________________________________________________________________________________________\n","tf.one_hot_4 (TFOpLambda)       (None, 10)           0           input_19[0][0]                   \n","__________________________________________________________________________________________________\n","input_18 (InputLayer)           [(None, 2)]          0                                            \n","__________________________________________________________________________________________________\n","tf.concat_4 (TFOpLambda)        (None, 20)           0           input_17[0][0]                   \n","                                                                 tf.one_hot_4[0][0]               \n","                                                                 input_18[0][0]                   \n","__________________________________________________________________________________________________\n","sequential_12 (Sequential)      (None, 28, 28, 1)    321633      tf.concat_4[0][0]                \n","==================================================================================================\n","Total params: 321,633\n","Trainable params: 308,897\n","Non-trainable params: 12,736\n","__________________________________________________________________________________________________\n","Model: \"discriminator\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_20 (InputLayer)           [(None, 28, 28, 1)]  0                                            \n","__________________________________________________________________________________________________\n","sequential_14 (Sequential)      (None, 32)           333920      input_20[0][0]                   \n","__________________________________________________________________________________________________\n","recognition (Sequential)        (None, 12)           796         sequential_14[0][0]              \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_8 (Sli (None, 2)            0           recognition[0][0]                \n","__________________________________________________________________________________________________\n","tf.math.tanh_4 (TFOpLambda)     (None, 2)            0           tf.__operators__.getitem_8[0][0] \n","__________________________________________________________________________________________________\n","dense_24 (Dense)                (None, 1)            33          sequential_14[0][0]              \n","__________________________________________________________________________________________________\n","tf.math.multiply_4 (TFOpLambda) (None, 2)            0           tf.math.tanh_4[0][0]             \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_9 (Sli (None, 10)           0           recognition[0][0]                \n","==================================================================================================\n","Total params: 334,749\n","Trainable params: 334,269\n","Non-trainable params: 480\n","__________________________________________________________________________________________________\n","ep=0 | time=0.3|t=0|d_acc=0.50|d_classacc=0.00|g_acc=0.09|d_loss=5.16|g_loss=5.16\n","ep=0 | time=24.9|t=400|d_acc=1.00|d_classacc=0.00|g_acc=0.08|d_loss=4.52|g_loss=9.80\n","ep=0 | time=25.0|t=800|d_acc=1.00|d_classacc=0.00|g_acc=0.11|d_loss=4.53|g_loss=10.84\n","ep=0 | time=24.8|t=1200|d_acc=1.00|d_classacc=0.00|g_acc=0.06|d_loss=4.47|g_loss=10.96\n","ep=0 | time=25.2|t=1600|d_acc=1.00|d_classacc=0.00|g_acc=0.08|d_loss=4.48|g_loss=11.13\n","ep=1 | time=20.3|t=0|d_acc=1.00|d_classacc=0.00|g_acc=0.12|d_loss=4.51|g_loss=11.04\n","ep=1 | time=25.0|t=400|d_acc=1.00|d_classacc=0.00|g_acc=0.09|d_loss=4.45|g_loss=10.81\n","ep=1 | time=24.8|t=800|d_acc=1.00|d_classacc=0.00|g_acc=0.12|d_loss=4.48|g_loss=11.67\n","ep=1 | time=25.1|t=1200|d_acc=1.00|d_classacc=0.00|g_acc=0.08|d_loss=4.45|g_loss=11.96\n","ep=1 | time=25.3|t=1600|d_acc=1.00|d_classacc=0.00|g_acc=0.11|d_loss=4.49|g_loss=12.14\n","ep=2 | time=19.7|t=0|d_acc=1.00|d_classacc=0.00|g_acc=0.11|d_loss=4.48|g_loss=10.32\n","ep=2 | time=24.9|t=400|d_acc=1.00|d_classacc=0.00|g_acc=0.08|d_loss=4.48|g_loss=12.68\n","ep=2 | time=24.8|t=800|d_acc=1.00|d_classacc=0.00|g_acc=0.08|d_loss=4.46|g_loss=13.61\n","ep=2 | time=24.7|t=1200|d_acc=1.00|d_classacc=0.00|g_acc=0.05|d_loss=4.51|g_loss=11.44\n","ep=2 | time=24.6|t=1600|d_acc=1.00|d_classacc=0.00|g_acc=0.09|d_loss=4.51|g_loss=13.08\n","ep=3 | time=19.5|t=0|d_acc=1.00|d_classacc=0.00|g_acc=0.09|d_loss=4.47|g_loss=12.12\n","ep=3 | time=24.7|t=400|d_acc=1.00|d_classacc=0.00|g_acc=0.03|d_loss=4.48|g_loss=13.46\n","ep=3 | time=24.5|t=800|d_acc=1.00|d_classacc=0.00|g_acc=0.16|d_loss=4.46|g_loss=13.69\n","ep=3 | time=24.7|t=1200|d_acc=1.00|d_classacc=0.00|g_acc=0.19|d_loss=4.46|g_loss=12.80\n","ep=3 | time=24.6|t=1600|d_acc=1.00|d_classacc=0.00|g_acc=0.14|d_loss=4.49|g_loss=14.43\n","ep=4 | time=19.7|t=0|d_acc=1.00|d_classacc=0.00|g_acc=0.09|d_loss=4.45|g_loss=12.51\n","ep=4 | time=24.6|t=400|d_acc=1.00|d_classacc=0.00|g_acc=0.12|d_loss=4.49|g_loss=10.47\n","ep=4 | time=24.6|t=800|d_acc=1.00|d_classacc=0.00|g_acc=0.08|d_loss=4.44|g_loss=11.91\n","ep=4 | time=24.4|t=1200|d_acc=1.00|d_classacc=0.00|g_acc=0.09|d_loss=4.50|g_loss=13.47\n","ep=4 | time=24.8|t=1600|d_acc=1.00|d_classacc=0.00|g_acc=0.03|d_loss=4.53|g_loss=13.99\n","ep=5 | time=19.5|t=0|d_acc=1.00|d_classacc=0.00|g_acc=0.14|d_loss=4.47|g_loss=12.38\n","ep=5 | time=25.8|t=400|d_acc=1.00|d_classacc=0.00|g_acc=0.06|d_loss=4.46|g_loss=14.00\n","ep=5 | time=25.0|t=800|d_acc=1.00|d_classacc=0.00|g_acc=0.17|d_loss=4.44|g_loss=15.67\n","ep=5 | time=24.8|t=1200|d_acc=1.00|d_classacc=0.00|g_acc=0.05|d_loss=4.47|g_loss=14.76\n","ep=5 | time=24.7|t=1600|d_acc=1.00|d_classacc=0.00|g_acc=0.16|d_loss=4.50|g_loss=14.03\n","ep=6 | time=19.6|t=0|d_acc=1.00|d_classacc=0.00|g_acc=0.08|d_loss=4.47|g_loss=13.41\n","ep=6 | time=24.7|t=400|d_acc=1.00|d_classacc=0.00|g_acc=0.06|d_loss=4.48|g_loss=12.68\n","ep=6 | time=24.6|t=800|d_acc=1.00|d_classacc=0.00|g_acc=0.08|d_loss=4.51|g_loss=13.39\n","ep=6 | time=24.7|t=1200|d_acc=1.00|d_classacc=0.00|g_acc=0.03|d_loss=4.50|g_loss=15.83\n","ep=6 | time=24.9|t=1600|d_acc=1.00|d_classacc=0.00|g_acc=0.14|d_loss=4.50|g_loss=14.37\n","ep=7 | time=19.1|t=0|d_acc=1.00|d_classacc=0.00|g_acc=0.14|d_loss=4.52|g_loss=15.86\n","ep=7 | time=24.7|t=400|d_acc=1.00|d_classacc=0.00|g_acc=0.09|d_loss=4.47|g_loss=17.62\n","ep=7 | time=24.9|t=800|d_acc=0.94|d_classacc=0.05|g_acc=0.12|d_loss=4.58|g_loss=7.32\n","ep=7 | time=25.0|t=1200|d_acc=0.83|d_classacc=0.03|g_acc=0.44|d_loss=3.85|g_loss=6.26\n","ep=7 | time=24.7|t=1600|d_acc=0.84|d_classacc=0.27|g_acc=0.98|d_loss=2.54|g_loss=3.16\n","ep=8 | time=19.7|t=0|d_acc=0.81|d_classacc=0.30|g_acc=0.98|d_loss=2.44|g_loss=2.90\n","ep=8 | time=24.7|t=400|d_acc=0.72|d_classacc=0.12|g_acc=1.00|d_loss=2.51|g_loss=3.48\n","ep=8 | time=25.0|t=800|d_acc=0.84|d_classacc=0.17|g_acc=0.98|d_loss=2.37|g_loss=3.26\n","ep=8 | time=25.2|t=1200|d_acc=0.73|d_classacc=0.14|g_acc=1.00|d_loss=2.45|g_loss=3.00\n","ep=8 | time=24.9|t=1600|d_acc=0.67|d_classacc=0.17|g_acc=1.00|d_loss=2.54|g_loss=3.07\n","ep=9 | time=19.2|t=0|d_acc=0.78|d_classacc=0.17|g_acc=1.00|d_loss=2.38|g_loss=3.15\n","ep=9 | time=24.7|t=400|d_acc=0.80|d_classacc=0.09|g_acc=0.98|d_loss=2.37|g_loss=3.12\n","ep=9 | time=25.9|t=800|d_acc=0.80|d_classacc=0.27|g_acc=1.00|d_loss=2.49|g_loss=2.78\n","ep=9 | time=25.2|t=1200|d_acc=0.75|d_classacc=0.03|g_acc=0.97|d_loss=2.40|g_loss=3.30\n","ep=9 | time=24.9|t=1600|d_acc=0.66|d_classacc=0.06|g_acc=0.98|d_loss=2.50|g_loss=3.57\n","ep=10 | time=20.0|t=0|d_acc=0.67|d_classacc=0.25|g_acc=0.98|d_loss=2.46|g_loss=2.85\n","ep=10 | time=24.7|t=400|d_acc=0.73|d_classacc=0.30|g_acc=1.00|d_loss=2.42|g_loss=2.76\n","ep=10 | time=24.9|t=800|d_acc=0.75|d_classacc=0.17|g_acc=1.00|d_loss=2.45|g_loss=2.92\n","ep=10 | time=24.8|t=1200|d_acc=0.75|d_classacc=0.02|g_acc=0.98|d_loss=2.38|g_loss=3.42\n","ep=10 | time=24.7|t=1600|d_acc=0.61|d_classacc=0.00|g_acc=1.00|d_loss=2.54|g_loss=3.76\n","ep=11 | time=19.4|t=0|d_acc=0.64|d_classacc=0.03|g_acc=1.00|d_loss=2.51|g_loss=3.25\n","ep=11 | time=25.3|t=400|d_acc=0.73|d_classacc=0.05|g_acc=1.00|d_loss=2.41|g_loss=3.05\n","ep=11 | time=24.8|t=800|d_acc=0.66|d_classacc=0.02|g_acc=1.00|d_loss=2.41|g_loss=3.49\n","ep=11 | time=24.8|t=1200|d_acc=0.59|d_classacc=0.16|g_acc=1.00|d_loss=2.59|g_loss=2.80\n","ep=11 | time=24.8|t=1600|d_acc=0.78|d_classacc=0.14|g_acc=1.00|d_loss=2.37|g_loss=3.05\n","ep=12 | time=19.1|t=0|d_acc=0.59|d_classacc=0.05|g_acc=1.00|d_loss=2.52|g_loss=3.27\n","ep=12 | time=24.7|t=400|d_acc=0.70|d_classacc=0.25|g_acc=1.00|d_loss=2.50|g_loss=2.73\n","ep=12 | time=25.0|t=800|d_acc=0.80|d_classacc=0.27|g_acc=1.00|d_loss=2.42|g_loss=2.75\n","ep=12 | time=25.0|t=1200|d_acc=0.62|d_classacc=0.12|g_acc=1.00|d_loss=2.53|g_loss=2.96\n","ep=12 | time=24.8|t=1600|d_acc=0.66|d_classacc=0.03|g_acc=1.00|d_loss=2.42|g_loss=3.02\n","ep=13 | time=20.3|t=0|d_acc=0.62|d_classacc=0.05|g_acc=1.00|d_loss=2.51|g_loss=3.38\n","ep=13 | time=24.8|t=800|d_acc=0.62|d_classacc=0.11|g_acc=1.00|d_loss=2.51|g_loss=2.81\n","ep=13 | time=24.8|t=1200|d_acc=0.61|d_classacc=0.08|g_acc=0.98|d_loss=2.49|g_loss=2.91\n","ep=13 | time=24.7|t=1600|d_acc=0.66|d_classacc=0.03|g_acc=1.00|d_loss=2.44|g_loss=3.09\n","ep=14 | time=19.3|t=0|d_acc=0.61|d_classacc=0.39|g_acc=0.97|d_loss=2.65|g_loss=2.67\n","ep=14 | time=24.6|t=400|d_acc=0.64|d_classacc=0.08|g_acc=1.00|d_loss=2.52|g_loss=2.98\n","ep=14 | time=24.9|t=800|d_acc=0.61|d_classacc=0.20|g_acc=1.00|d_loss=2.52|g_loss=2.73\n","ep=14 | time=24.7|t=1200|d_acc=0.69|d_classacc=0.05|g_acc=1.00|d_loss=2.42|g_loss=2.91\n","ep=14 | time=24.8|t=1600|d_acc=0.59|d_classacc=0.22|g_acc=1.00|d_loss=2.55|g_loss=2.64\n","ep=15 | time=19.0|t=0|d_acc=0.75|d_classacc=0.03|g_acc=1.00|d_loss=2.43|g_loss=2.93\n","ep=15 | time=24.7|t=400|d_acc=0.64|d_classacc=0.09|g_acc=1.00|d_loss=2.51|g_loss=2.91\n","ep=15 | time=24.8|t=800|d_acc=0.61|d_classacc=0.08|g_acc=1.00|d_loss=2.59|g_loss=2.98\n","ep=15 | time=24.8|t=1200|d_acc=0.67|d_classacc=0.12|g_acc=1.00|d_loss=2.52|g_loss=2.76\n","ep=15 | time=24.5|t=1600|d_acc=0.58|d_classacc=0.12|g_acc=1.00|d_loss=2.50|g_loss=2.88\n","ep=16 | time=20.5|t=0|d_acc=0.58|d_classacc=0.20|g_acc=1.00|d_loss=2.56|g_loss=2.62\n","ep=16 | time=24.6|t=400|d_acc=0.62|d_classacc=0.09|g_acc=1.00|d_loss=2.62|g_loss=3.01\n","ep=16 | time=24.5|t=800|d_acc=0.62|d_classacc=0.16|g_acc=1.00|d_loss=2.54|g_loss=2.65\n","ep=16 | time=24.7|t=1200|d_acc=0.59|d_classacc=0.08|g_acc=1.00|d_loss=2.56|g_loss=2.70\n","ep=16 | time=24.4|t=1600|d_acc=0.73|d_classacc=0.08|g_acc=0.98|d_loss=2.44|g_loss=2.94\n","ep=17 | time=19.0|t=0|d_acc=0.64|d_classacc=0.28|g_acc=1.00|d_loss=2.49|g_loss=2.59\n","ep=17 | time=24.5|t=400|d_acc=0.61|d_classacc=0.11|g_acc=1.00|d_loss=2.50|g_loss=2.94\n","ep=17 | time=24.5|t=800|d_acc=0.70|d_classacc=0.19|g_acc=1.00|d_loss=2.42|g_loss=2.64\n","ep=17 | time=24.5|t=1200|d_acc=0.53|d_classacc=0.19|g_acc=1.00|d_loss=2.60|g_loss=2.61\n","ep=17 | time=24.3|t=1600|d_acc=0.61|d_classacc=0.06|g_acc=1.00|d_loss=2.51|g_loss=2.78\n","ep=18 | time=18.9|t=0|d_acc=0.69|d_classacc=0.02|g_acc=1.00|d_loss=2.41|g_loss=2.94\n","ep=18 | time=24.6|t=400|d_acc=0.58|d_classacc=0.06|g_acc=1.00|d_loss=2.51|g_loss=2.78\n","ep=18 | time=24.4|t=800|d_acc=0.58|d_classacc=0.33|g_acc=1.00|d_loss=2.53|g_loss=2.48\n","ep=18 | time=24.4|t=1200|d_acc=0.62|d_classacc=0.17|g_acc=1.00|d_loss=2.55|g_loss=2.65\n","ep=18 | time=24.5|t=1600|d_acc=0.53|d_classacc=0.17|g_acc=1.00|d_loss=2.56|g_loss=2.70\n","ep=19 | time=18.7|t=0|d_acc=0.62|d_classacc=0.11|g_acc=1.00|d_loss=2.45|g_loss=2.81\n","ep=19 | time=24.4|t=400|d_acc=0.69|d_classacc=0.17|g_acc=1.00|d_loss=2.48|g_loss=2.63\n","ep=19 | time=24.3|t=800|d_acc=0.55|d_classacc=0.08|g_acc=1.00|d_loss=2.51|g_loss=2.82\n","ep=19 | time=24.8|t=1200|d_acc=0.52|d_classacc=0.16|g_acc=1.00|d_loss=2.58|g_loss=2.67\n","ep=19 | time=24.5|t=1600|d_acc=0.66|d_classacc=0.08|g_acc=1.00|d_loss=2.48|g_loss=2.75\n","ep=20 | time=18.8|t=0|d_acc=0.64|d_classacc=0.11|g_acc=1.00|d_loss=2.49|g_loss=2.71\n","ep=20 | time=24.4|t=400|d_acc=0.55|d_classacc=0.20|g_acc=1.00|d_loss=2.55|g_loss=2.60\n","ep=20 | time=24.5|t=800|d_acc=0.58|d_classacc=0.12|g_acc=1.00|d_loss=2.54|g_loss=2.65\n","ep=20 | time=24.3|t=1200|d_acc=0.59|d_classacc=0.28|g_acc=1.00|d_loss=2.51|g_loss=2.52\n","ep=20 | time=24.5|t=1600|d_acc=0.56|d_classacc=0.30|g_acc=1.00|d_loss=2.55|g_loss=2.56\n","ep=21 | time=20.7|t=0|d_acc=0.56|d_classacc=0.14|g_acc=1.00|d_loss=2.54|g_loss=2.70\n","ep=21 | time=24.4|t=400|d_acc=0.64|d_classacc=0.09|g_acc=1.00|d_loss=2.47|g_loss=2.64\n","ep=21 | time=24.4|t=800|d_acc=0.56|d_classacc=0.08|g_acc=1.00|d_loss=2.53|g_loss=2.66\n","ep=21 | time=24.7|t=1200|d_acc=0.58|d_classacc=0.23|g_acc=1.00|d_loss=2.53|g_loss=2.57\n","ep=21 | time=24.4|t=1600|d_acc=0.45|d_classacc=0.16|g_acc=1.00|d_loss=2.60|g_loss=2.61\n","ep=22 | time=18.7|t=0|d_acc=0.55|d_classacc=0.08|g_acc=1.00|d_loss=2.56|g_loss=2.60\n","ep=22 | time=24.6|t=400|d_acc=0.59|d_classacc=0.11|g_acc=1.00|d_loss=2.49|g_loss=2.74\n","ep=22 | time=24.4|t=800|d_acc=0.45|d_classacc=0.31|g_acc=1.00|d_loss=2.54|g_loss=2.52\n","ep=22 | time=24.2|t=1200|d_acc=0.56|d_classacc=0.20|g_acc=1.00|d_loss=2.54|g_loss=2.60\n","ep=22 | time=24.5|t=1600|d_acc=0.55|d_classacc=0.09|g_acc=1.00|d_loss=2.55|g_loss=2.65\n","ep=23 | time=18.8|t=0|d_acc=0.58|d_classacc=0.30|g_acc=1.00|d_loss=2.57|g_loss=2.52\n","ep=23 | time=24.3|t=400|d_acc=0.59|d_classacc=0.06|g_acc=1.00|d_loss=2.52|g_loss=2.71\n","ep=23 | time=24.7|t=800|d_acc=0.53|d_classacc=0.06|g_acc=1.00|d_loss=2.51|g_loss=2.68\n","ep=23 | time=24.5|t=1200|d_acc=0.61|d_classacc=0.06|g_acc=1.00|d_loss=2.50|g_loss=2.65\n","ep=23 | time=24.5|t=1600|d_acc=0.53|d_classacc=0.14|g_acc=1.00|d_loss=2.51|g_loss=2.68\n","ep=24 | time=18.7|t=0|d_acc=0.52|d_classacc=0.20|g_acc=1.00|d_loss=2.55|g_loss=2.67\n","ep=24 | time=24.6|t=400|d_acc=0.59|d_classacc=0.16|g_acc=1.00|d_loss=2.51|g_loss=2.59\n","ep=24 | time=24.4|t=800|d_acc=0.55|d_classacc=0.06|g_acc=0.98|d_loss=2.48|g_loss=2.92\n","ep=24 | time=24.4|t=1200|d_acc=0.66|d_classacc=0.11|g_acc=1.00|d_loss=2.48|g_loss=2.59\n","ep=24 | time=24.5|t=1600|d_acc=0.59|d_classacc=0.05|g_acc=1.00|d_loss=2.47|g_loss=2.77\n","ep=25 | time=18.9|t=0|d_acc=0.55|d_classacc=0.08|g_acc=1.00|d_loss=2.55|g_loss=2.66\n","ep=25 | time=24.4|t=400|d_acc=0.50|d_classacc=0.14|g_acc=1.00|d_loss=2.53|g_loss=2.64\n","ep=25 | time=24.0|t=800|d_acc=0.58|d_classacc=0.17|g_acc=1.00|d_loss=2.52|g_loss=2.58\n","ep=25 | time=24.5|t=1200|d_acc=0.56|d_classacc=0.11|g_acc=1.00|d_loss=2.53|g_loss=2.56\n","ep=25 | time=24.6|t=1600|d_acc=0.61|d_classacc=0.08|g_acc=1.00|d_loss=2.51|g_loss=2.59\n","ep=26 | time=21.1|t=0|d_acc=0.58|d_classacc=0.02|g_acc=1.00|d_loss=2.55|g_loss=2.71\n","ep=26 | time=24.2|t=400|d_acc=0.58|d_classacc=0.08|g_acc=1.00|d_loss=2.50|g_loss=2.70\n","ep=26 | time=23.9|t=800|d_acc=0.61|d_classacc=0.06|g_acc=1.00|d_loss=2.52|g_loss=2.67\n","ep=26 | time=24.0|t=1200|d_acc=0.56|d_classacc=0.11|g_acc=1.00|d_loss=2.54|g_loss=2.65\n","ep=26 | time=23.9|t=1600|d_acc=0.61|d_classacc=0.06|g_acc=1.00|d_loss=2.50|g_loss=2.69\n","ep=27 | time=18.6|t=0|d_acc=0.52|d_classacc=0.12|g_acc=1.00|d_loss=2.55|g_loss=2.71\n","ep=27 | time=23.9|t=400|d_acc=0.50|d_classacc=0.14|g_acc=1.00|d_loss=2.59|g_loss=2.60\n","ep=27 | time=23.9|t=800|d_acc=0.55|d_classacc=0.09|g_acc=1.00|d_loss=2.53|g_loss=2.67\n","ep=27 | time=23.8|t=1200|d_acc=0.56|d_classacc=0.14|g_acc=1.00|d_loss=2.52|g_loss=2.61\n","ep=27 | time=23.8|t=1600|d_acc=0.55|d_classacc=0.09|g_acc=1.00|d_loss=2.54|g_loss=2.60\n","ep=28 | time=18.3|t=0|d_acc=0.61|d_classacc=0.11|g_acc=1.00|d_loss=2.50|g_loss=2.64\n","ep=28 | time=23.9|t=400|d_acc=0.56|d_classacc=0.08|g_acc=1.00|d_loss=2.55|g_loss=2.60\n","ep=28 | time=24.5|t=800|d_acc=0.62|d_classacc=0.16|g_acc=1.00|d_loss=2.50|g_loss=2.53\n","ep=28 | time=24.1|t=1200|d_acc=0.53|d_classacc=0.02|g_acc=1.00|d_loss=2.56|g_loss=2.64\n","ep=28 | time=24.2|t=1600|d_acc=0.55|d_classacc=0.20|g_acc=1.00|d_loss=2.58|g_loss=2.50\n","ep=29 | time=18.6|t=0|d_acc=0.58|d_classacc=0.14|g_acc=1.00|d_loss=2.56|g_loss=2.60\n","ep=29 | time=23.8|t=400|d_acc=0.52|d_classacc=0.19|g_acc=1.00|d_loss=2.55|g_loss=2.54\n","ep=29 | time=23.9|t=800|d_acc=0.53|d_classacc=0.12|g_acc=1.00|d_loss=2.55|g_loss=2.64\n","ep=29 | time=23.8|t=1200|d_acc=0.53|d_classacc=0.03|g_acc=1.00|d_loss=2.55|g_loss=2.71\n","ep=29 | time=24.0|t=1600|d_acc=0.53|d_classacc=0.12|g_acc=1.00|d_loss=2.57|g_loss=2.56\n","ep=30 | time=18.4|t=0|d_acc=0.59|d_classacc=0.17|g_acc=0.98|d_loss=2.57|g_loss=2.53\n","ep=30 | time=24.0|t=400|d_acc=0.56|d_classacc=0.06|g_acc=1.00|d_loss=2.53|g_loss=2.59\n","ep=30 | time=23.8|t=800|d_acc=0.53|d_classacc=0.05|g_acc=1.00|d_loss=2.55|g_loss=2.67\n","ep=30 | time=23.8|t=1200|d_acc=0.53|d_classacc=0.09|g_acc=1.00|d_loss=2.55|g_loss=2.60\n","ep=30 | time=23.9|t=1600|d_acc=0.50|d_classacc=0.12|g_acc=1.00|d_loss=2.59|g_loss=2.61\n","ep=31 | time=18.5|t=0|d_acc=0.55|d_classacc=0.09|g_acc=1.00|d_loss=2.51|g_loss=2.69\n","ep=31 | time=23.8|t=400|d_acc=0.58|d_classacc=0.00|g_acc=1.00|d_loss=2.53|g_loss=2.67\n","ep=31 | time=24.0|t=800|d_acc=0.58|d_classacc=0.05|g_acc=1.00|d_loss=2.54|g_loss=2.66\n","ep=31 | time=24.3|t=1200|d_acc=0.56|d_classacc=0.11|g_acc=1.00|d_loss=2.53|g_loss=2.69\n","ep=31 | time=24.5|t=1600|d_acc=0.47|d_classacc=0.12|g_acc=1.00|d_loss=2.58|g_loss=2.56\n","ep=32 | time=18.7|t=0|d_acc=0.53|d_classacc=0.20|g_acc=0.98|d_loss=2.68|g_loss=2.63\n","ep=32 | time=24.4|t=400|d_acc=0.52|d_classacc=0.09|g_acc=1.00|d_loss=2.51|g_loss=2.64\n","ep=32 | time=24.3|t=800|d_acc=0.61|d_classacc=0.12|g_acc=1.00|d_loss=2.51|g_loss=2.52\n","ep=32 | time=24.3|t=1200|d_acc=0.56|d_classacc=0.09|g_acc=1.00|d_loss=2.50|g_loss=2.60\n","ep=32 | time=24.3|t=1600|d_acc=0.47|d_classacc=0.09|g_acc=1.00|d_loss=2.53|g_loss=2.63\n","ep=33 | time=21.6|t=0|d_acc=0.58|d_classacc=0.19|g_acc=1.00|d_loss=2.52|g_loss=2.53\n","ep=33 | time=24.3|t=400|d_acc=0.58|d_classacc=0.09|g_acc=1.00|d_loss=2.51|g_loss=2.61\n","ep=33 | time=24.6|t=800|d_acc=0.58|d_classacc=0.06|g_acc=1.00|d_loss=2.53|g_loss=2.67\n","ep=33 | time=24.6|t=1200|d_acc=0.61|d_classacc=0.11|g_acc=1.00|d_loss=2.54|g_loss=2.56\n","ep=33 | time=24.4|t=1600|d_acc=0.47|d_classacc=0.05|g_acc=1.00|d_loss=2.57|g_loss=2.72\n","ep=34 | time=18.7|t=0|d_acc=0.50|d_classacc=0.14|g_acc=1.00|d_loss=2.53|g_loss=2.62\n","ep=34 | time=24.6|t=400|d_acc=0.58|d_classacc=0.12|g_acc=1.00|d_loss=2.53|g_loss=2.58\n","ep=34 | time=24.3|t=800|d_acc=0.56|d_classacc=0.06|g_acc=1.00|d_loss=2.53|g_loss=2.59\n","ep=34 | time=24.5|t=1200|d_acc=0.50|d_classacc=0.03|g_acc=1.00|d_loss=2.53|g_loss=2.64\n","ep=34 | time=24.6|t=1600|d_acc=0.55|d_classacc=0.06|g_acc=1.00|d_loss=2.53|g_loss=2.65\n","ep=35 | time=19.1|t=0|d_acc=0.59|d_classacc=0.17|g_acc=1.00|d_loss=2.56|g_loss=2.53\n","ep=35 | time=24.6|t=400|d_acc=0.52|d_classacc=0.08|g_acc=1.00|d_loss=2.57|g_loss=2.60\n","ep=35 | time=24.4|t=800|d_acc=0.55|d_classacc=0.08|g_acc=0.98|d_loss=2.54|g_loss=2.67\n","ep=35 | time=24.5|t=1200|d_acc=0.53|d_classacc=0.11|g_acc=1.00|d_loss=2.55|g_loss=2.63\n","ep=35 | time=24.7|t=1600|d_acc=0.58|d_classacc=0.09|g_acc=1.00|d_loss=2.50|g_loss=2.58\n","ep=36 | time=18.9|t=0|d_acc=0.55|d_classacc=0.06|g_acc=1.00|d_loss=2.55|g_loss=2.68\n","ep=36 | time=24.5|t=400|d_acc=0.55|d_classacc=0.06|g_acc=1.00|d_loss=2.53|g_loss=2.57\n","ep=36 | time=24.5|t=800|d_acc=0.48|d_classacc=0.14|g_acc=1.00|d_loss=2.56|g_loss=2.59\n","ep=36 | time=24.7|t=1200|d_acc=0.53|d_classacc=0.08|g_acc=1.00|d_loss=2.54|g_loss=2.65\n","ep=36 | time=24.4|t=1600|d_acc=0.48|d_classacc=0.03|g_acc=1.00|d_loss=2.57|g_loss=2.69\n","ep=37 | time=18.9|t=0|d_acc=0.45|d_classacc=0.19|g_acc=1.00|d_loss=2.61|g_loss=2.58\n","ep=37 | time=24.3|t=400|d_acc=0.53|d_classacc=0.11|g_acc=1.00|d_loss=2.55|g_loss=2.63\n","ep=37 | time=24.3|t=800|d_acc=0.58|d_classacc=0.02|g_acc=1.00|d_loss=2.50|g_loss=2.64\n","ep=37 | time=24.4|t=1200|d_acc=0.58|d_classacc=0.05|g_acc=1.00|d_loss=2.48|g_loss=2.66\n","ep=37 | time=24.3|t=1600|d_acc=0.53|d_classacc=0.03|g_acc=1.00|d_loss=2.55|g_loss=2.58\n","ep=38 | time=18.8|t=0|d_acc=0.67|d_classacc=0.09|g_acc=1.00|d_loss=2.50|g_loss=2.64\n","ep=38 | time=24.8|t=400|d_acc=0.53|d_classacc=0.06|g_acc=1.00|d_loss=2.52|g_loss=2.58\n","ep=38 | time=24.4|t=800|d_acc=0.53|d_classacc=0.06|g_acc=1.00|d_loss=2.54|g_loss=2.62\n","ep=38 | time=24.1|t=1200|d_acc=0.55|d_classacc=0.02|g_acc=1.00|d_loss=2.54|g_loss=2.58\n","ep=38 | time=24.2|t=1600|d_acc=0.50|d_classacc=0.00|g_acc=1.00|d_loss=2.51|g_loss=2.71\n","ep=39 | time=18.7|t=0|d_acc=0.52|d_classacc=0.09|g_acc=1.00|d_loss=2.53|g_loss=2.62\n","ep=39 | time=24.1|t=400|d_acc=0.55|d_classacc=0.05|g_acc=1.00|d_loss=2.55|g_loss=2.58\n","ep=39 | time=24.1|t=800|d_acc=0.59|d_classacc=0.11|g_acc=1.00|d_loss=2.49|g_loss=2.58\n","ep=39 | time=24.3|t=1200|d_acc=0.56|d_classacc=0.03|g_acc=1.00|d_loss=2.54|g_loss=2.59\n","ep=39 | time=24.0|t=1600|d_acc=0.50|d_classacc=0.02|g_acc=1.00|d_loss=2.54|g_loss=2.67\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-480a59a9c5e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_half_batch_ds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInfoGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRAND_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTYLE_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLABEL_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SHAPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFIX_STD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTYLE_SCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-480a59a9c5e4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(gan, ds)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0msave_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0mcvt_gif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'cvt_gif' is not defined"]}]}]}