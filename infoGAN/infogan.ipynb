{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"infogan.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lcIaPYQJEU_e","executionInfo":{"status":"ok","timestamp":1648903944632,"user_tz":-480,"elapsed":2752,"user":{"displayName":"brian2","userId":"02776227907876420321"}},"outputId":"f30fb582-b332-44e4-dbb0-8c6677452f47"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"aotwpkOnEXbx","executionInfo":{"status":"ok","timestamp":1648903944633,"user_tz":-480,"elapsed":8,"user":{"displayName":"brian2","userId":"02776227907876420321"}}},"source":["!cd /content/drive/MyDrive/張雲南/infogan"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jn1zHO3uDmxC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d48eb859-de0e-414d-a00c-06bece6ea9d6","executionInfo":{"status":"ok","timestamp":1648907934006,"user_tz":-480,"elapsed":3989378,"user":{"displayName":"brian2","userId":"02776227907876420321"}}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","from tensorflow.keras.layers import Dense, Input, BatchNormalization, LeakyReLU, Dropout\n","from tensorflow.keras.layers import Conv2D, Flatten, Reshape, Conv2DTranspose, ReLU\n","import time\n","import os\n","import matplotlib.pyplot as plt\n","\n","#----------------------- utils -----------------------\n","\n","_b_acc = None\n","_c_acc = None\n","\n","\n","def binary_accuracy(label, pred):\n","    global _b_acc\n","    if _b_acc is None:\n","        _b_acc = tf.keras.metrics.BinaryAccuracy()\n","    _b_acc.reset_states()\n","    _b_acc.update_state(label, pred)\n","    return _b_acc.result()\n","\n","def class_accuracy(label, pred):\n","    global _c_acc\n","    if _c_acc is None:\n","        _c_acc = tf.keras.metrics.SparseCategoricalAccuracy()\n","    _c_acc.reset_states()\n","    _c_acc.update_state(label, pred)\n","    return _c_acc.result()\n","\n","def save_weights(model):\n","    name = model.__class__.__name__.lower()\n","    os.makedirs(\"./models/{}\".format(name), exist_ok=True)\n","    model.save_weights(\"./models/{}/model.ckpt\".format(name))\n","\n","# ------------------- get_half_batch_ds -------------------\n","\n","def _process_x(x):\n","    return tf.expand_dims(tf.cast(x, tf.float32), axis=3) / 255. * 2 - 1\n","\n","def get_half_batch_ds(batch_size):\n","    return get_ds(batch_size//2)\n","\n","def get_ds(batch_size):\n","    (x, y), _ = keras.datasets.mnist.load_data()\n","    x = _process_x(x)\n","    y = tf.cast(y, tf.int32)\n","    ds = tf.data.Dataset.from_tensor_slices((x, y)).cache().shuffle(1024).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n","    return ds\n","\n","# ------------------- gan_cnn -------------------\n","\n","def mnist_uni_gen_cnn(input_shape):\n","    return keras.Sequential([\n","        # [n, latent] -> [n, 7 * 7 * 128] -> [n, 7, 7, 128]\n","        Dense(7 * 7 * 128, input_shape=input_shape),\n","        BatchNormalization(),\n","        ReLU(),\n","        Reshape((7, 7, 128)),\n","        # -> [n, 14, 14, 64]\n","        Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same'),\n","        BatchNormalization(),\n","        ReLU(),\n","        # -> [n, 28, 28, 32]\n","        Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same'),\n","        BatchNormalization(),\n","        ReLU(),\n","        # -> [n, 28, 28, 1]\n","        Conv2D(1, (4, 4), padding='same', activation=keras.activations.tanh)\n","    ])\n","\n","\n","def mnist_uni_disc_cnn(input_shape=(28, 28, 1), use_bn=True):\n","    model = keras.Sequential()\n","    # [n, 28, 28, n] -> [n, 14, 14, 64]\n","    model.add(Conv2D(64, (4, 4), strides=(2, 2), padding='same', input_shape=input_shape))\n","    if use_bn:\n","        model.add(BatchNormalization())\n","    model.add(LeakyReLU())\n","    model.add(Dropout(0.3))\n","    # -> [n, 7, 7, 128]\n","    model.add(Conv2D(128, (4, 4), strides=(2, 2), padding='same'))\n","    if use_bn:\n","        model.add(BatchNormalization())\n","    model.add(LeakyReLU())\n","    model.add(Dropout(0.3))\n","    model.add(Flatten())\n","    return model\n","\n","# ----------------------------------------------------------\n","\n","def save_gan(model, ep, **kwargs):\n","    img_label = np.arange(0, model.label_dim).astype(np.int32).repeat(10, axis=0)\n","    img_style = np.concatenate([np.linspace(-model.style_scale, model.style_scale, 10)] * 10).reshape((100, 1)).repeat(model.style_dim, axis=1).astype(np.float32)\n","    img_info = img_label, img_style\n","    imgs = model.predict(img_info)\n","    _save_gan(ep, imgs, show_label=False)\n","    \n","    plt.clf()\n","    plt.close()\n","\n","def _save_gan(ep, imgs, show_label=False, nc=10, nr=10):\n","    if not isinstance(imgs, np.ndarray):\n","        imgs = imgs.numpy()\n","    if imgs.ndim > 3:\n","        imgs = np.squeeze(imgs, axis=-1)\n","    imgs = _img_recenter(imgs)\n","    plt.clf()\n","    plt.figure(0, (nc * 2, nr * 2))\n","    for c in range(nc):\n","        for r in range(nr):\n","            i = r * nc + c\n","            plt.subplot(nr, nc, i + 1)\n","            plt.imshow(imgs[i], cmap=\"gray_r\")\n","            plt.axis(\"off\")\n","    plt.savefig('/content/drive/MyDrive/張雲南/infogan/img/' + f'{ep}.png')\n","    plt.close()\n","\n","def _img_recenter(img):\n","    return (img + 1) * 255 / 2\n","\n","# ----------------------------------------------------------\n","\n","class InfoGAN(keras.Model):\n","    def __init__(self, rand_dim, style_dim, label_dim, img_shape, fix_std=True, style_scale=2):\n","        super().__init__()\n","        self.rand_dim, self.style_dim, self.label_dim = rand_dim, style_dim, label_dim\n","        self.img_shape = img_shape\n","        self.fix_std = fix_std\n","        self.style_scale = style_scale\n","\n","        self.g = self._get_generator()\n","        self.d = self._get_discriminator()\n","\n","        self.opt = keras.optimizers.Adam(0.0002, beta_1=0.5)\n","        self.loss_bool = keras.losses.BinaryCrossentropy(from_logits=True, reduction=\"none\")\n","\n","    def call(self, img_info, training=None, mask=None):\n","        img_label, img_style = img_info\n","        noise = tf.random.normal((len(img_label), self.rand_dim))\n","        if isinstance(img_label, np.ndarray):\n","            img_label = tf.convert_to_tensor(img_label, dtype=tf.int32)\n","        if isinstance(img_style, np.ndarray):\n","            img_style = tf.convert_to_tensor(img_style, dtype=tf.float32)\n","        return self.g.call([noise, img_label, img_style], training=training)\n","\n","    def _get_discriminator(self):\n","        img = Input(shape=self.img_shape)\n","        s = keras.Sequential([\n","            mnist_uni_disc_cnn(self.img_shape),\n","            Dense(32),\n","            BatchNormalization(),\n","            LeakyReLU(),\n","            Dropout(0.5),\n","        ])\n","        style_dim = self.style_dim if self.fix_std else self.style_dim * 2\n","        q = keras.Sequential([\n","            Dense(16, input_shape=(32,)),\n","            BatchNormalization(),\n","            LeakyReLU(),\n","            Dense(style_dim+self.label_dim)\n","        ], name=\"recognition\")\n","        o = s(img)\n","        o_bool = Dense(1)(o)\n","        o_q = q(o)\n","        if self.fix_std:\n","            q_style = self.style_scale*tf.tanh(o_q[:, :style_dim])\n","        else:\n","            q_style = tf.concat(\n","                (self.style_scale * tf.tanh(o_q[:, :style_dim//2]), tf.nn.relu(o_q[:, style_dim//2:style_dim])),\n","                axis=1)\n","        q_label = o_q[:, -self.label_dim:]\n","        model = keras.Model(img, [o_bool, q_style, q_label], name=\"discriminator\")\n","        model.summary()\n","        return model\n","\n","    def _get_generator(self):\n","        latent_dim = self.rand_dim + self.label_dim + self.style_dim\n","        noise = Input(shape=(self.rand_dim,))\n","        style = Input(shape=(self.style_dim, ))\n","        label = Input(shape=(), dtype=tf.int32)\n","        label_onehot = tf.one_hot(label, depth=self.label_dim)\n","        model_in = tf.concat((noise, label_onehot, style), axis=1)\n","        s = mnist_uni_gen_cnn((latent_dim,))\n","        o = s(model_in)\n","        model = keras.Model([noise, label, style], o, name=\"generator\")\n","        model.summary()\n","        return model\n","\n","# ------------------------------------------- high light -----------------------------------------------------\n","# info_loss (q_model loss)\n","    def loss_mutual_info(self, style, pred_style, label, pred_label):\n","        # label loss\n","        categorical_loss = keras.losses.sparse_categorical_crossentropy(label, pred_label, from_logits=True)  \n","\n","        # 選擇 std 為固定還是隨機\n","        if self.fix_std:\n","            style_mean = pred_style\n","            style_std = tf.ones_like(pred_style)\n","        else:\n","            split = pred_style.shape[1]//2\n","            style_mean, style_std = pred_style[:split], pred_style[split:]\n","            style_std = tf.sqrt(tf.exp(style_std))\n","\n","        # continuous latent code loss\n","        epsilon = (style - style_mean) / (style_std + 1e-5)\n","        ll_continuous = tf.reduce_sum(\n","            - 0.5 * tf.math.log(2 * np.pi) - tf.math.log(style_std + 1e-5) - 0.5 * tf.square(epsilon),\n","            axis=1,\n","        )\n","\n","        # loss\n","        loss = categorical_loss - ll_continuous\n","        return loss\n","\n","# --------------------------------------------------------------------------------------------------------------\n","\n","    def train_d(self, real_fake_img, real_fake_d_label, fake_img_label, fake_style):\n","        with tf.GradientTape() as tape:\n","            pred_bool, pred_style, pred_class = self.d.call(real_fake_img, training=True)\n","            info_split = len(real_fake_d_label)\n","            real_fake_pred_bool = pred_bool[:info_split]\n","            loss_bool = self.loss_bool(real_fake_d_label, real_fake_pred_bool)\n","            fake_pred_style = pred_style[-info_split:]\n","            fake_pred_label = pred_class[-info_split:]\n","            loss_info = self.loss_mutual_info(fake_style, fake_pred_style, fake_img_label, fake_pred_label)\n","            loss = tf.reduce_mean(loss_bool + LAMBDA * loss_info)\n","        grads = tape.gradient(loss, self.d.trainable_variables)\n","        self.opt.apply_gradients(zip(grads, self.d.trainable_variables))\n","        return loss, binary_accuracy(real_fake_d_label, real_fake_pred_bool), class_accuracy(fake_img_label, fake_pred_label)\n","\n","    def train_g(self, random_img_label, random_img_style):\n","        d_label = tf.ones((len(random_img_label), 1), tf.float32)   # let d think generated images are real\n","        with tf.GradientTape() as tape:\n","            g_img = self.call([random_img_label, random_img_style], training=True)\n","            pred_bool, pred_style, pred_class = self.d.call(g_img, training=False)\n","            loss_bool = self.loss_bool(d_label, pred_bool)\n","            loss_info = self.loss_mutual_info(random_img_style, pred_style, random_img_label, pred_class)\n","            loss = tf.reduce_mean(loss_bool + LAMBDA * loss_info)\n","        grads = tape.gradient(loss, self.g.trainable_variables)\n","        self.opt.apply_gradients(zip(grads, self.g.trainable_variables))\n","        return loss, g_img, binary_accuracy(d_label, pred_bool)\n","\n","    def step(self, real_img):\n","        random_img_label = tf.convert_to_tensor(np.random.randint(0, 10, len(real_img)*2), dtype=tf.int32)\n","        random_img_style = tf.random.uniform((len(real_img)*2, self.style_dim), -self.style_scale, self.style_scale)\n","        g_loss, g_img, g_bool_acc = self.train_g(random_img_label, random_img_style)\n","\n","        real_fake_img = tf.concat((real_img, g_img), axis=0)    # 32+64\n","        real_fake_d_label = tf.concat(      # 32+32\n","            (tf.ones((len(real_img), 1), tf.float32), tf.zeros((len(g_img)//2, 1), tf.float32)), axis=0)\n","        d_loss, d_bool_acc, d_class_acc = self.train_d(real_fake_img, real_fake_d_label, random_img_label, random_img_style)\n","        return d_loss, d_bool_acc, g_loss, g_bool_acc, random_img_label, d_class_acc\n","\n","\n","def train(gan, ds):\n","    t0 = time.time()\n","    for ep in range(EPOCH):\n","        for t, (real_img, _) in enumerate(ds):\n","            d_loss, d_bool_acc, g_loss, g_bool_acc, g_img_label, d_class_acc = gan.step(real_img)\n","            if t % 400 == 0:\n","                t1 = time.time()\n","                print(\"ep={} | time={:.1f}|t={}|d_acc={:.2f}|d_classacc={:.2f}|g_acc={:.2f}|d_loss={:.2f}|g_loss={:.2f}\".format(\n","                    ep, t1-t0, t, d_bool_acc.numpy(), g_bool_acc.numpy(), d_class_acc.numpy(), d_loss.numpy(), g_loss.numpy(), ))\n","                t0 = t1\n","        save_gan(gan, ep)\n","    save_weights(gan)\n","\n","\n","if __name__ == \"__main__\":\n","    STYLE_DIM = 2\n","    LABEL_DIM = 10\n","    RAND_DIM = 8\n","    LAMBDA = 1\n","    IMG_SHAPE = (28, 28, 1)\n","    FIX_STD = True\n","    STYLE_SCALE = 1\n","    BATCH_SIZE = 64\n","    EPOCH = 20\n","\n","    d = get_half_batch_ds(BATCH_SIZE)\n","    m = InfoGAN(RAND_DIM, STYLE_DIM, LABEL_DIM, IMG_SHAPE, FIX_STD, STYLE_SCALE)\n","    train(m, d)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"generator\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_3 (InputLayer)           [(None,)]            0           []                               \n","                                                                                                  \n"," input_1 (InputLayer)           [(None, 8)]          0           []                               \n","                                                                                                  \n"," tf.one_hot (TFOpLambda)        (None, 10)           0           ['input_3[0][0]']                \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 2)]          0           []                               \n","                                                                                                  \n"," tf.concat (TFOpLambda)         (None, 20)           0           ['input_1[0][0]',                \n","                                                                  'tf.one_hot[0][0]',             \n","                                                                  'input_2[0][0]']                \n","                                                                                                  \n"," sequential (Sequential)        (None, 28, 28, 1)    321633      ['tf.concat[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 321,633\n","Trainable params: 308,897\n","Non-trainable params: 12,736\n","__________________________________________________________________________________________________\n","Model: \"discriminator\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_4 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n","                                                                                                  \n"," sequential_2 (Sequential)      (None, 32)           333920      ['input_4[0][0]']                \n","                                                                                                  \n"," recognition (Sequential)       (None, 12)           796         ['sequential_2[0][0]']           \n","                                                                                                  \n"," tf.__operators__.getitem (Slic  (None, 2)           0           ['recognition[0][0]']            \n"," ingOpLambda)                                                                                     \n","                                                                                                  \n"," tf.math.tanh (TFOpLambda)      (None, 2)            0           ['tf.__operators__.getitem[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," dense_4 (Dense)                (None, 1)            33          ['sequential_2[0][0]']           \n","                                                                                                  \n"," tf.math.multiply (TFOpLambda)  (None, 2)            0           ['tf.math.tanh[0][0]']           \n","                                                                                                  \n"," tf.__operators__.getitem_1 (Sl  (None, 10)          0           ['recognition[0][0]']            \n"," icingOpLambda)                                                                                   \n","                                                                                                  \n","==================================================================================================\n","Total params: 334,749\n","Trainable params: 334,269\n","Non-trainable params: 480\n","__________________________________________________________________________________________________\n","ep=0 | time=1.7|t=0|d_acc=0.50|d_classacc=0.00|g_acc=0.14|d_loss=5.15|g_loss=5.17\n","ep=0 | time=41.9|t=400|d_acc=1.00|d_classacc=0.00|g_acc=0.31|d_loss=3.92|g_loss=8.55\n","ep=0 | time=42.1|t=800|d_acc=0.98|d_classacc=0.00|g_acc=1.00|d_loss=2.14|g_loss=8.41\n","ep=0 | time=43.5|t=1200|d_acc=1.00|d_classacc=0.00|g_acc=1.00|d_loss=2.08|g_loss=8.55\n","ep=0 | time=42.5|t=1600|d_acc=1.00|d_classacc=0.00|g_acc=1.00|d_loss=1.96|g_loss=8.81\n","ep=1 | time=32.4|t=0|d_acc=1.00|d_classacc=0.00|g_acc=1.00|d_loss=1.97|g_loss=9.46\n","ep=1 | time=42.3|t=400|d_acc=1.00|d_classacc=0.00|g_acc=1.00|d_loss=2.01|g_loss=9.18\n","ep=1 | time=41.8|t=800|d_acc=1.00|d_classacc=0.00|g_acc=0.98|d_loss=2.06|g_loss=8.45\n","ep=1 | time=42.5|t=1200|d_acc=1.00|d_classacc=0.00|g_acc=1.00|d_loss=2.11|g_loss=10.32\n","ep=1 | time=41.8|t=1600|d_acc=1.00|d_classacc=0.00|g_acc=1.00|d_loss=1.99|g_loss=7.87\n","ep=2 | time=31.7|t=0|d_acc=0.97|d_classacc=0.00|g_acc=0.98|d_loss=2.10|g_loss=6.44\n","ep=2 | time=42.3|t=400|d_acc=1.00|d_classacc=0.00|g_acc=1.00|d_loss=1.94|g_loss=8.03\n","ep=2 | time=43.0|t=800|d_acc=0.95|d_classacc=0.11|g_acc=1.00|d_loss=2.17|g_loss=5.58\n","ep=2 | time=43.2|t=1200|d_acc=0.84|d_classacc=0.09|g_acc=0.95|d_loss=2.45|g_loss=4.17\n","ep=2 | time=42.0|t=1600|d_acc=0.72|d_classacc=0.12|g_acc=0.88|d_loss=2.96|g_loss=3.22\n","ep=3 | time=32.2|t=0|d_acc=0.75|d_classacc=0.02|g_acc=0.98|d_loss=2.42|g_loss=3.90\n","ep=3 | time=42.3|t=400|d_acc=0.72|d_classacc=0.14|g_acc=1.00|d_loss=2.44|g_loss=3.13\n","ep=3 | time=41.9|t=800|d_acc=0.70|d_classacc=0.05|g_acc=1.00|d_loss=2.44|g_loss=3.39\n","ep=3 | time=41.8|t=1200|d_acc=0.80|d_classacc=0.06|g_acc=1.00|d_loss=2.32|g_loss=3.15\n","ep=3 | time=41.4|t=1600|d_acc=0.88|d_classacc=0.00|g_acc=1.00|d_loss=2.29|g_loss=3.65\n","ep=4 | time=37.1|t=0|d_acc=0.73|d_classacc=0.11|g_acc=0.98|d_loss=2.41|g_loss=3.33\n","ep=4 | time=41.9|t=400|d_acc=0.70|d_classacc=0.14|g_acc=1.00|d_loss=2.42|g_loss=3.07\n","ep=4 | time=41.6|t=800|d_acc=0.73|d_classacc=0.05|g_acc=0.98|d_loss=2.51|g_loss=3.17\n","ep=4 | time=41.4|t=1200|d_acc=0.84|d_classacc=0.25|g_acc=0.98|d_loss=2.39|g_loss=2.88\n","ep=4 | time=40.8|t=1600|d_acc=0.80|d_classacc=0.09|g_acc=0.98|d_loss=2.39|g_loss=2.88\n","ep=5 | time=32.0|t=0|d_acc=0.73|d_classacc=0.20|g_acc=1.00|d_loss=2.46|g_loss=2.77\n","ep=5 | time=42.1|t=400|d_acc=0.69|d_classacc=0.05|g_acc=1.00|d_loss=2.50|g_loss=3.06\n","ep=5 | time=42.8|t=800|d_acc=0.83|d_classacc=0.05|g_acc=0.98|d_loss=2.38|g_loss=3.15\n","ep=5 | time=42.4|t=1200|d_acc=0.70|d_classacc=0.36|g_acc=1.00|d_loss=2.51|g_loss=2.58\n","ep=5 | time=42.4|t=1600|d_acc=0.59|d_classacc=0.19|g_acc=1.00|d_loss=2.61|g_loss=2.87\n","ep=6 | time=35.5|t=0|d_acc=0.75|d_classacc=0.02|g_acc=1.00|d_loss=2.33|g_loss=3.39\n","ep=6 | time=44.1|t=400|d_acc=0.66|d_classacc=0.25|g_acc=0.98|d_loss=2.55|g_loss=2.72\n","ep=6 | time=43.1|t=800|d_acc=0.66|d_classacc=0.11|g_acc=1.00|d_loss=2.52|g_loss=2.92\n","ep=6 | time=41.6|t=1200|d_acc=0.53|d_classacc=0.31|g_acc=1.00|d_loss=2.81|g_loss=2.68\n","ep=6 | time=41.6|t=1600|d_acc=0.70|d_classacc=0.17|g_acc=1.00|d_loss=2.39|g_loss=3.08\n","ep=7 | time=31.0|t=0|d_acc=0.70|d_classacc=0.19|g_acc=1.00|d_loss=2.49|g_loss=2.67\n","ep=7 | time=42.3|t=400|d_acc=0.73|d_classacc=0.11|g_acc=1.00|d_loss=2.43|g_loss=2.97\n","ep=7 | time=42.3|t=800|d_acc=0.66|d_classacc=0.08|g_acc=1.00|d_loss=2.46|g_loss=2.95\n","ep=7 | time=42.1|t=1200|d_acc=0.62|d_classacc=0.06|g_acc=1.00|d_loss=2.49|g_loss=2.93\n","ep=7 | time=42.2|t=1600|d_acc=0.78|d_classacc=0.11|g_acc=1.00|d_loss=2.35|g_loss=3.08\n","ep=8 | time=32.3|t=0|d_acc=0.78|d_classacc=0.05|g_acc=1.00|d_loss=2.36|g_loss=3.05\n","ep=8 | time=42.4|t=400|d_acc=0.66|d_classacc=0.05|g_acc=1.00|d_loss=2.49|g_loss=2.99\n","ep=8 | time=42.1|t=800|d_acc=0.69|d_classacc=0.12|g_acc=1.00|d_loss=2.44|g_loss=2.86\n","ep=8 | time=41.7|t=1200|d_acc=0.66|d_classacc=0.27|g_acc=0.98|d_loss=2.55|g_loss=2.67\n","ep=8 | time=41.9|t=1600|d_acc=0.62|d_classacc=0.06|g_acc=1.00|d_loss=2.48|g_loss=3.03\n","ep=9 | time=31.8|t=0|d_acc=0.58|d_classacc=0.02|g_acc=1.00|d_loss=2.65|g_loss=3.23\n","ep=9 | time=41.7|t=400|d_acc=0.61|d_classacc=0.11|g_acc=1.00|d_loss=2.48|g_loss=2.72\n","ep=9 | time=41.6|t=800|d_acc=0.62|d_classacc=0.05|g_acc=1.00|d_loss=2.48|g_loss=2.93\n","ep=9 | time=42.1|t=1200|d_acc=0.61|d_classacc=0.06|g_acc=1.00|d_loss=2.50|g_loss=3.04\n","ep=9 | time=42.8|t=1600|d_acc=0.66|d_classacc=0.14|g_acc=1.00|d_loss=2.49|g_loss=2.71\n","ep=10 | time=31.2|t=0|d_acc=0.67|d_classacc=0.17|g_acc=1.00|d_loss=2.41|g_loss=2.92\n","ep=10 | time=40.8|t=400|d_acc=0.72|d_classacc=0.06|g_acc=1.00|d_loss=2.44|g_loss=2.91\n","ep=10 | time=41.1|t=800|d_acc=0.77|d_classacc=0.09|g_acc=1.00|d_loss=2.43|g_loss=2.63\n","ep=10 | time=40.6|t=1200|d_acc=0.64|d_classacc=0.12|g_acc=1.00|d_loss=2.52|g_loss=2.72\n","ep=10 | time=41.3|t=1600|d_acc=0.58|d_classacc=0.16|g_acc=1.00|d_loss=2.50|g_loss=3.00\n","ep=11 | time=32.4|t=0|d_acc=0.67|d_classacc=0.12|g_acc=0.98|d_loss=2.49|g_loss=2.78\n","ep=11 | time=41.5|t=400|d_acc=0.58|d_classacc=0.25|g_acc=1.00|d_loss=2.51|g_loss=2.57\n","ep=11 | time=41.7|t=800|d_acc=0.61|d_classacc=0.09|g_acc=1.00|d_loss=2.49|g_loss=2.72\n","ep=11 | time=41.4|t=1200|d_acc=0.58|d_classacc=0.03|g_acc=1.00|d_loss=2.51|g_loss=2.86\n","ep=11 | time=41.0|t=1600|d_acc=0.72|d_classacc=0.05|g_acc=1.00|d_loss=2.45|g_loss=2.98\n","ep=12 | time=31.3|t=0|d_acc=0.58|d_classacc=0.25|g_acc=1.00|d_loss=2.58|g_loss=2.54\n","ep=12 | time=42.5|t=400|d_acc=0.62|d_classacc=0.08|g_acc=1.00|d_loss=2.50|g_loss=2.76\n","ep=12 | time=41.2|t=800|d_acc=0.59|d_classacc=0.23|g_acc=1.00|d_loss=2.55|g_loss=2.56\n","ep=12 | time=40.9|t=1200|d_acc=0.48|d_classacc=0.14|g_acc=1.00|d_loss=2.66|g_loss=2.75\n","ep=12 | time=41.6|t=1600|d_acc=0.55|d_classacc=0.28|g_acc=1.00|d_loss=2.55|g_loss=2.55\n","ep=13 | time=31.4|t=0|d_acc=0.69|d_classacc=0.08|g_acc=1.00|d_loss=2.44|g_loss=2.79\n","ep=13 | time=41.1|t=400|d_acc=0.55|d_classacc=0.11|g_acc=1.00|d_loss=2.52|g_loss=2.79\n","ep=13 | time=42.1|t=800|d_acc=0.56|d_classacc=0.08|g_acc=1.00|d_loss=2.46|g_loss=2.82\n","ep=13 | time=41.4|t=1200|d_acc=0.58|d_classacc=0.16|g_acc=1.00|d_loss=2.48|g_loss=2.61\n","ep=13 | time=40.2|t=1600|d_acc=0.72|d_classacc=0.14|g_acc=1.00|d_loss=2.49|g_loss=2.58\n","ep=14 | time=31.3|t=0|d_acc=0.56|d_classacc=0.16|g_acc=1.00|d_loss=2.55|g_loss=2.75\n","ep=14 | time=40.5|t=400|d_acc=0.55|d_classacc=0.05|g_acc=1.00|d_loss=2.51|g_loss=2.73\n","ep=14 | time=42.6|t=800|d_acc=0.58|d_classacc=0.05|g_acc=1.00|d_loss=2.48|g_loss=2.86\n","ep=14 | time=40.9|t=1200|d_acc=0.56|d_classacc=0.14|g_acc=1.00|d_loss=2.56|g_loss=2.63\n","ep=14 | time=41.0|t=1600|d_acc=0.56|d_classacc=0.12|g_acc=1.00|d_loss=2.56|g_loss=2.67\n","ep=15 | time=31.2|t=0|d_acc=0.59|d_classacc=0.17|g_acc=1.00|d_loss=2.54|g_loss=2.73\n","ep=15 | time=40.3|t=400|d_acc=0.58|d_classacc=0.14|g_acc=1.00|d_loss=2.55|g_loss=2.65\n","ep=15 | time=41.2|t=800|d_acc=0.52|d_classacc=0.09|g_acc=1.00|d_loss=2.54|g_loss=2.65\n","ep=15 | time=40.8|t=1200|d_acc=0.58|d_classacc=0.16|g_acc=1.00|d_loss=2.57|g_loss=2.65\n","ep=15 | time=41.0|t=1600|d_acc=0.59|d_classacc=0.19|g_acc=1.00|d_loss=2.56|g_loss=2.60\n","ep=16 | time=31.9|t=0|d_acc=0.58|d_classacc=0.09|g_acc=1.00|d_loss=2.51|g_loss=2.73\n","ep=16 | time=42.3|t=400|d_acc=0.59|d_classacc=0.09|g_acc=1.00|d_loss=2.54|g_loss=2.68\n","ep=16 | time=41.3|t=800|d_acc=0.66|d_classacc=0.05|g_acc=1.00|d_loss=2.50|g_loss=2.60\n","ep=16 | time=41.3|t=1200|d_acc=0.50|d_classacc=0.25|g_acc=0.98|d_loss=2.64|g_loss=2.61\n","ep=16 | time=42.7|t=1600|d_acc=0.44|d_classacc=0.31|g_acc=1.00|d_loss=2.61|g_loss=2.51\n","ep=17 | time=31.2|t=0|d_acc=0.66|d_classacc=0.14|g_acc=1.00|d_loss=2.50|g_loss=2.67\n","ep=17 | time=41.0|t=400|d_acc=0.55|d_classacc=0.05|g_acc=1.00|d_loss=2.51|g_loss=2.68\n","ep=17 | time=41.3|t=800|d_acc=0.61|d_classacc=0.03|g_acc=1.00|d_loss=2.50|g_loss=2.69\n","ep=17 | time=40.8|t=1200|d_acc=0.53|d_classacc=0.05|g_acc=1.00|d_loss=2.52|g_loss=2.77\n","ep=17 | time=41.3|t=1600|d_acc=0.53|d_classacc=0.12|g_acc=1.00|d_loss=2.56|g_loss=2.62\n","ep=18 | time=33.7|t=0|d_acc=0.56|d_classacc=0.09|g_acc=1.00|d_loss=2.57|g_loss=2.66\n","ep=18 | time=41.5|t=400|d_acc=0.55|d_classacc=0.19|g_acc=1.00|d_loss=2.55|g_loss=2.56\n","ep=18 | time=41.4|t=800|d_acc=0.56|d_classacc=0.14|g_acc=1.00|d_loss=2.54|g_loss=2.57\n","ep=18 | time=41.6|t=1200|d_acc=0.50|d_classacc=0.12|g_acc=1.00|d_loss=2.54|g_loss=2.59\n","ep=18 | time=41.5|t=1600|d_acc=0.48|d_classacc=0.16|g_acc=1.00|d_loss=2.64|g_loss=2.62\n","ep=19 | time=31.3|t=0|d_acc=0.47|d_classacc=0.09|g_acc=1.00|d_loss=2.55|g_loss=2.73\n","ep=19 | time=41.6|t=400|d_acc=0.64|d_classacc=0.20|g_acc=1.00|d_loss=2.52|g_loss=2.60\n","ep=19 | time=41.1|t=800|d_acc=0.53|d_classacc=0.06|g_acc=1.00|d_loss=2.54|g_loss=2.66\n","ep=19 | time=40.9|t=1200|d_acc=0.48|d_classacc=0.12|g_acc=1.00|d_loss=2.54|g_loss=2.61\n","ep=19 | time=40.7|t=1600|d_acc=0.52|d_classacc=0.14|g_acc=1.00|d_loss=2.60|g_loss=2.54\n"]}]}]}