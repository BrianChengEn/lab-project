{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"wgan.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1mT_e4C1Yr_915i9aLUlJct_xxXm6kyCe","authorship_tag":"ABX9TyP1qrBwFpd70sV15QtkaS/f"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264},"id":"_ckOJwFti-KX","executionInfo":{"status":"ok","timestamp":1648966911443,"user_tz":-480,"elapsed":492,"user":{"displayName":"Brian","userId":"12158858202818726983"}},"outputId":"2f138dd0-7209-41c4-a54c-112ff671a636"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","a1 = np.random.rand(250) + 2\n","a2 = np.random.rand(250) + 7\n","b = np.zeros(500)\n","a = np.concatenate((a1,a2), axis=0)\n","plt.scatter(a,b)\n","plt.show()"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"EsZawNhQjAQj","executionInfo":{"status":"ok","timestamp":1648966914599,"user_tz":-480,"elapsed":3163,"user":{"displayName":"Brian","userId":"12158858202818726983"}}},"source":["from numpy import hstack\n","from numpy import zeros\n","from numpy import ones\n","from numpy.random import rand\n","from numpy.random import randn\n","from keras.layers import Dense\n","from keras import Input, Model\n","from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n","from matplotlib import pyplot\n","from keras import backend as K\n","from keras.constraints import Constraint\n","from keras.initializers import RandomNormal\n","import tensorflow as tf"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1IIxrUnxGyrWR2EIhhsLkWH6BhZMdVIwc"},"id":"9JolWCIGpM1O","executionInfo":{"status":"ok","timestamp":1648968256278,"user_tz":-480,"elapsed":1341685,"user":{"displayName":"Brian","userId":"12158858202818726983"}},"outputId":"0e9ec6ad-e1d0-477a-c269-1c9b0e583025"},"source":["def wasserstein_loss(y_true, y_pred):\n","\t  return K.mean(y_true * y_pred)\n"," \n","class ClipConstraint(Constraint):\n","    def __init__(self, clip_value):\n","      self.clip_value = clip_value\n","\n","    # clip model weights to hypercube\n","    def __call__(self, weights):\n","      return K.clip(weights, -self.clip_value, self.clip_value)\n","\n","    # get the config\n","    def get_config(self):\n","  \t  return {'clip_value': self.clip_value}\n","\n","def define_discriminator():\n","    init = RandomNormal(stddev=0.02)\n","    const = ClipConstraint(0.05)\n","    inputs = Input(shape=(1,))\n","    x = Dense(8, kernel_initializer=init, kernel_constraint=const, activation='relu')(inputs)\n","    x = Dense(16, kernel_initializer=init, kernel_constraint=const, activation='relu')(x)\n","    x = Dense(32, kernel_initializer=init, kernel_constraint=const, activation='relu')(x)\n","    x = Dense(64, kernel_initializer=init, kernel_constraint=const, activation='relu')(x)\n","    outputs = Dense(1, activation='linear')(x)\n","\n","    model = Model(inputs,outputs)\n","    opt = RMSprop(learning_rate=0.00005)\n","    model.compile(loss=wasserstein_loss, optimizer=opt)\n","    return model\n","\n","def define_generator(latent_dim, n_outputs=1):\n","    inputs = Input(shape=(latent_dim,))\n","    x = Dense(64, activation='relu')(inputs)\n","    x = Dense(32, activation='relu')(x)\n","    x = Dense(16, activation='relu')(x)\n","    x = Dense(8, activation='relu')(x)\n","    outputs = Dense(n_outputs, activation='linear')(x)\n","\n","    model = Model(inputs, outputs)\n","    return model\n","\n","def define_gan(generator, discriminator):\n","    discriminator.trainable = False\n","    gen_noise = generator.input\n","    gen_output = generator.output\n","    gan_output = discriminator(gen_output)\n","    model = Model(gen_noise, gan_output)\n","    opt = RMSprop(learning_rate=0.00008)\n","    model.compile(loss=wasserstein_loss, optimizer=opt)\n","    return model\n","    \n","def generate_real_samples(n):\n","    ix = np.random.randint(0, 500, n)\n","    X = a[ix]\n","\n","    y = -ones((n, 1))\n","    return X, y\n","\n","def generate_latent_points(latent_dim, n):\n","    x_input = randn(latent_dim * n)\n","    x_input = x_input.reshape(n, latent_dim)\n","    return x_input\n","\n","def generate_fake_samples(generator, latent_dim, n):\n","    x_input = generate_latent_points(latent_dim, n)\n","    x_input = tf.convert_to_tensor(x_input, dtype=tf.float32)\n","    X = generator(x_input)\n","    y = ones((n, 1))\n","    y = tf.convert_to_tensor(y, dtype=tf.float32)\n","    return X, y\n","    \n","def summarize_performance(epoch, generator, discriminator, latent_dim, n=50):\n","    x_real, y_real = generate_real_samples(n)\n","    acc_real = discriminator.evaluate(x_real, y_real, verbose=0)\n","    x_fake, y_fake = generate_fake_samples(generator, latent_dim, n)\n","    acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n","\n","    ll = np.linspace(0, 10, 50, endpoint=False)\n","    ll = ll.astype('float32')\n","    aa = discriminator(ll)\n","\n","    c = np.zeros(n)\n","    plt.plot(ll,aa)\n","    plt.scatter(x_real[0:], c, alpha=0.6)\n","    plt.scatter(x_fake, c, alpha=0.6)\n","    plt.show()\n","    plt.close()\n","\n","def plot_history(d1_hist, d2_hist, g_hist):\n","    # plot history\n","    plt.plot(d1_hist, label='crit_real')\n","    plt.plot(d2_hist, label='crit_fake')\n","    plt.plot(g_hist, label='gen')\n","    plt.legend()\n","    plt.show()\n","\n","def train(g_model, d_model, gan_model, latent_dim, n_epochs=15000, n_batch=64, n_eval=50):\n","    half_batch = int(n_batch / 2)\n","\n","    c1_hist, c2_hist, g_hist = list(), list(), list()\n","    for i in range(n_epochs):\n","        c1_tmp, c2_tmp = list(), list()\n","        for j in range(3):\n","            x_real, y_real = generate_real_samples(n_batch)\n","            x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_batch)\n","            c_loss1 = d_model.train_on_batch(x_real, y_real)\n","            c_loss2 = d_model.train_on_batch(x_fake, y_fake)\n","            c1_tmp.append(c_loss1)\n","            c2_tmp.append(c_loss2)\n","\n","        for j in range(1):\n","            x_gan = generate_latent_points(latent_dim, n_batch)\n","            y_gan = -ones((n_batch, 1))\n","            g_loss = gan_model.train_on_batch(x_gan, y_gan)\n","\n","        c1_hist.append(np.mean(c1_tmp))\n","        c2_hist.append(np.mean(c2_tmp))\n","        g_hist.append(g_loss)\n","\n","        if (i+1) % n_eval == 0:\n","            summarize_performance(i, g_model, d_model, latent_dim)\n","            print(i)\n","            plot_history(c1_hist, c2_hist, g_hist)\n","\n","latent_dim = 100\n","discriminator = define_discriminator()\n","generator = define_generator(latent_dim)\n","gan_model = define_gan(generator, discriminator)\n","train(generator, discriminator, gan_model, latent_dim)"],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}